# -*- coding: utf-8 -*-
"""World_Happiness_report_Linear_Regression_Random_Forest_Global

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JHxTcwpZRtdf3D0cAx9NJQPs4mqs1PGF

•	Country name ⇨ Nom du pays concerné par les données.

  •	Year ⇨ Année correspondant à la collecte des données ou à leur extrapolation.

  •	Life Ladder ⇨ Indicateur de bien-être subjectif basé sur les réponses à la question Cantril life ladder, représentant l’évaluation personnelle de la vie sur une échelle de 0 (pire vie possible) à 10 (meilleure vie possible).

  •	Log GDP per capita ⇨ Logarithme naturel du PIB par habitant, mesuré en parité de pouvoir d’achat (PPA) avec des prix constants de 2017.

  •	Social support ⇨ Moyenne nationale des réponses affirmatives à la question sur la possibilité de compter sur des proches en cas de besoin.

  •	Healthy life expectancy at birth ⇨ Espérance de vie en bonne santé à la naissance, estimée à partir des données de l’OMS, interpolées et extrapolées si nécessaire.

  •	Freedom to make life choices ⇨ Moyenne nationale des réponses à la question sur la satisfaction vis-à-vis de la liberté de choix dans sa vie.

  •	Generosity ⇨ Résiduel de la régression de la réponse à la question sur les dons aux œuvres de charité au cours du dernier mois sur le PIB par habitant.

  •	Perceptions of corruption ⇨ Moyenne nationale des perceptions de la corruption dans les gouvernements et les entreprises, basée sur les réponses aux enquêtes du Gallup World Poll.

  •	Positive affect ⇨ Moyenne des indicateurs positifs comme le rire, le plaisir et les activités intéressantes vécues pendant une journée typique.

  •	Negative affect ⇨ Moyenne des indicateurs négatifs comme l’inquiétude, la tristesse et la colère vécues pendant une journée typique.
"""

import pandas as pd
import plotly.express as px

df = pd.read_excel("/content/DataForTable2.1 (1).xls")
df.info()
df.describe()

"""## Fill Missing values by filtering by country and using bfill or other"""

df_clean = df.dropna()
df_clean["Country name"].nunique()
df_clean.info()

#HeatMap de Correlation

import seaborn as sns

sns.heatmap(df_clean[['Life Ladder', 'Log GDP per capita',
       'Social support', 'Healthy life expectancy at birth',
       'Freedom to make life choices', 'Generosity',
       'Perceptions of corruption', 'Positive affect', 'Negative affect']].corr(), annot=True)

import pandas as pd
import numpy as np
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant

# Exemple de jeu de données
# Créez un DataFrame ou chargez vos propres données
df_clean


X = df_clean.drop(columns=["Life Ladder","Country name", 'year'])

# Étape 2 : Calculer le VIF pour chaque variable
vif_data = pd.DataFrame()
vif_data["Feature"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

# Afficher les résultats
print(vif_data)

#Random forest model

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

X = df_clean.drop(columns=['Life Ladder', 'Country name','year'])
y = df_clean['Life Ladder']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

X

from sklearn.preprocessing import StandardScaler

std_scaler = StandardScaler()
scaled_X_train = std_scaler.fit_transform(X_train)

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(scaled_X_train,y_train)

X_test_scaled = std_scaler.transform(X_test)

model.score(X_test_scaled,y_test)

X_train.columns

model.coef_

import matplotlib.pyplot as plt
import numpy as np

# Obtenir les coefficients et les noms des caractéristiques
coefficients = model.coef_
feature_names = X_train.columns

# Créer le graphique en barres
plt.bar(feature_names, coefficients)

# Ajouter des étiquettes et un titre
plt.xlabel("Caractéristiques")
plt.ylabel("Coefficients")
plt.title("Coefficients de régression linéaire")

# Faire pivoter les étiquettes de l'axe des x pour une meilleure lisibilité
plt.xticks(rotation=90)

# Afficher le graphique
plt.show()

import pandas as pd

# Créer un DataFrame avec les coefficients et les noms des caractéristiques
data = {'Feature': X_train.columns, 'Coefficient': model.coef_}
df_export = pd.DataFrame(data)

# Transposer le DataFrame pour que les noms des caractéristiques soient en colonnes
df_export = df_export.transpose()

# Définir la première ligne comme en-tête de colonne
df_export.columns = df_export.iloc[0]
df_export = df_export[1:]

# Enregistrer le DataFrame dans un fichier CSV
df_export.to_csv('coefficients.csv', index=False)

"""### Random Forest"""

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
clf = rf_model.fit(X_train, y_train)

clf.score(X_test,y_test)



importance = clf.feature_importances_

import matplotlib.pyplot as plt

# Assuming you have already trained your Random Forest model (rf_model) and calculated feature importances (importance)

# Get feature names from df_clean
feature_names = df_clean.drop(columns=['Life Ladder', 'Country name','year']).columns

# Create the bar plot
plt.bar(range(X.shape[1]), importance)
plt.xticks(range(X.shape[1]), feature_names, rotation=90)  # Use feature_names here
plt.title("Feature Importance in Random Forest")
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Assuming you have already trained your Random Forest model (rf_model) and calculated feature importances (importance)

# Get feature names from df_clean
feature_names = df_clean.drop(columns=['Life Ladder', 'Country name','year']).columns

# Sort features by importance in descending order
sorted_indices = np.argsort(importance)[::-1]  # Get indices of sorted importances (descending)
sorted_features = feature_names[sorted_indices]
sorted_importance = importance[sorted_indices]

# Create the horizontal bar plot
plt.barh(range(len(sorted_features)), sorted_importance, align='center')
plt.yticks(range(len(sorted_features)), sorted_features)  # Label features on the y-axis
plt.gca().invert_yaxis()  # Invert y-axis for descending order
plt.xlabel("Importance")
plt.title("Feature Importance in Random Forest")
plt.show()

import pandas as pd

# Créez un dictionnaire avec les données
data = {'Feature': feature_names, 'Importance': importance}

# Créez un DataFrame pandas
df_importance = pd.DataFrame(data)

# Enregistrez le DataFrame dans un fichier CSV
df_importance.to_csv('feature_importance.csv', index=False)

"""Tracer les coefficients de la regression lineaire"""