# -*- coding: utf-8 -*-
"""Project_features_for_Happiness_Augmented_feature_random_Forest

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nVSgkKcNy073so4UTM5f1nPZUXNG0Fv4

```
# Es ce qu'il y a une variation de critère de definition du bonheur selon si un pays est dev ebn dev ou sous dev

```
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/Data_Happiness.csv')

df_clean = df.dropna()
df_clean.info()

df_clean['Category'].value_counts()

df.columns

df_en_dev = df_clean.loc[df['Category'] == 'En Développement']
df_dev = df_clean.loc[df['Category'] == 'Développé']
df_sous_dev = df_clean.loc[df['Category'] == 'Sous-Développé']

df_en_dev.info()

"""## Random Forest df_en_dev"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
X = df_en_dev.drop(columns=['Life Ladder', 'Country name','year','region','sub-region','Category'])
y = df_en_dev['Life Ladder']
X_train, X_test, y_train, y_test = train_test_split(X, y)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
clf = rf_model.fit(X_train, y_train)

importance = clf.feature_importances_

import matplotlib.pyplot as plt
import numpy as np

# Assuming you have already trained your Random Forest model (rf_model) and calculated feature importances (importance)

# Get feature names from df_en_dev
feature_names = df_en_dev.drop(columns=['Life Ladder', 'Country name','year']).columns

# Sort features by importance in descending order
sorted_indices = np.argsort(importance)[::-1]  # Get indices of sorted importances (descending)
sorted_features = feature_names[sorted_indices]
sorted_importance = importance[sorted_indices]

# Create the horizontal bar plot
plt.barh(range(len(sorted_features)), sorted_importance, align='center')
plt.yticks(range(len(sorted_features)), sorted_features)  # Label features on the y-axis
plt.gca().invert_yaxis()  # Invert y-axis for descending order
plt.xlabel("Importance")
plt.title("Feature Importance in Random Forest")
plt.show()

"""•	Positive affect ⇨ Moyenne des indicateurs positifs comme le rire, le plaisir et les activités intéressantes vécues pendant une journée typique.

  •	Social support ⇨ Moyenne nationale des réponses affirmatives à la question sur la possibilité de compter sur des proches en cas de besoin.

  •	Log GDP per capita ⇨ parité de pouvoir d’achat (PPA) avec des prix constants de 2017.

  •	Healthy life expectancy at birth ⇨ Espérance de vie en bonne santé à la naissance, estimée à partir des données de l’OMS, interpolées et extrapolées si nécessaire.



 Target = Life Ladder ⇨ Indicateur de bien-être sur une échelle de 0 (pire vie possible) à 10 (meilleure vie possible).

## Random Forest df_dev
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
X = df_dev.drop(columns=['Life Ladder', 'Country name','year','region','sub-region','Category'])
y = df_dev['Life Ladder']

X_train, X_test, y_train, y_test = train_test_split(X, y)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

clf = rf_model.fit(X_train, y_train)

importance = clf.feature_importances_

import matplotlib.pyplot as plt
import numpy as np

# Assuming you have already trained your Random Forest model (rf_model) and calculated feature importances (importance)

# Get feature names from df_en_dev
feature_names = df_dev.drop(columns=['Life Ladder', 'Country name','year']).columns

# Sort features by importance in descending order
sorted_indices = np.argsort(importance)[::-1]  # Get indices of sorted importances (descending)
sorted_features = feature_names[sorted_indices]
sorted_importance = importance[sorted_indices]

# Create the horizontal bar plot
plt.barh(range(len(sorted_features)), sorted_importance, align='center')
plt.yticks(range(len(sorted_features)), sorted_features)  # Label features on the y-axis
plt.gca().invert_yaxis()  # Invert y-axis for descending order
plt.xlabel("Importance")
plt.title("Feature Importance in Random Forest")
plt.show()

"""• Log GDP per capita ⇨ parité de pouvoir d’achat (PPA) avec des prix constants de 2017.


•	Freedom to make life choices ⇨ Moyenne nationale des réponses à la question sur la satisfaction vis-à-vis de la liberté de choix dans sa vie.


• Positive affect ⇨ Moyenne des indicateurs positifs comme le rire, le plaisir et les activités intéressantes vécues pendant une journée typique.

•	Generosity ⇨ Résiduel de la régression de la réponse à la question sur les dons aux œuvres de charité au cours du dernier mois sur le PIB par habitant.


Target = Life Ladder ⇨ Indicateur de bien-être sur une échelle de 0 (pire vie possible) à 10 (meilleure vie possible).

## Random Forest df_sous_dev
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
X = df_sous_dev.drop(columns=['Life Ladder', 'Country name','year','region','sub-region','Category'])
y = df_sous_dev['Life Ladder']

X_train, X_test, y_train, y_test = train_test_split(X, y)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

clf = rf_model.fit(X_train, y_train)

importance = clf.feature_importances_

import matplotlib.pyplot as plt
import numpy as np

# Assuming you have already trained your Random Forest model (rf_model) and calculated feature importances (importance)

# Get feature names from df_en_dev
feature_names = df_sous_dev.drop(columns=['Life Ladder', 'Country name','year']).columns

# Sort features by importance in descending order
sorted_indices = np.argsort(importance)[::-1]  # Get indices of sorted importances (descending)
sorted_features = feature_names[sorted_indices]
sorted_importance = importance[sorted_indices]

# Create the horizontal bar plot
plt.barh(range(len(sorted_features)), sorted_importance, align='center')
plt.yticks(range(len(sorted_features)), sorted_features)  # Label features on the y-axis
plt.gca().invert_yaxis()  # Invert y-axis for descending order
plt.xlabel("Importance")
plt.title("Feature Importance in Random Forest")
plt.show()

"""•	Log GDP per capita ⇨ Logarithme naturel du PIB par habitant, mesuré en parité de pouvoir d’achat (PPA) avec des prix constants de 2017.

•	Healthy life expectancy at birth ⇨ Espérance de vie en bonne santé à la naissance, estimée à partir des données de l’OMS, interpolées et extrapolées si nécessaire.

•	Positive affect ⇨ Moyenne des indicateurs positifs comme le rire, le plaisir et les activités intéressantes vécues pendant une journée typique.

•	Social support ⇨ Moyenne nationale des réponses affirmatives à la question sur la possibilité de compter sur des proches en cas de besoin.

Target = Life Ladder ⇨ Indicateur de bien-être sur une échelle de 0 (pire vie possible) à 10 (meilleure vie possible).

"""